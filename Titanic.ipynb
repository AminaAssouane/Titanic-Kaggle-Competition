{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"input/test.csv\")\n",
    "test_shape = test.shape\n",
    "\n",
    "train = pd.read_csv(\"input/train.csv\")\n",
    "train_shape = train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a new column named \"Age_categories\" that adds a label depending on the age of the person ex : \n",
    "# between 5 and 12, we would have the label \"child\", between 60 and 100, the label \"senior\"\n",
    "\n",
    "def process_age(df,cut_points,label_names):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5) # We first fill all the blank places (where there is no age) with the number -0.5\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names) # That way when we add \"age_categories\" it will be labeled as \"missing\"\n",
    "    return df\n",
    "\n",
    "cut_points = [-1,0, 5, 12, 18, 35, 60, 100]\n",
    "label_names = [\"Missing\", 'Infant', \"Child\", 'Teenager', \"Young Adult\", 'Adult', 'Senior']\n",
    "\n",
    "train = process_age(train,cut_points,label_names)\n",
    "test = process_age(test,cut_points,label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add columns to our Data that indicate \"1\" for existence of information and \"0\" for not for two main reasons : \n",
    "# 1. For the \"Pclass\" column, we add these dummies to remove the relationship between 1, 2 and 3 that has no meaning\n",
    "# 2. We add dummies for the Sex and Age_categories columns because most machine learning algorithms can't understand \n",
    "# text labels, so we have to convert our values into numbers.\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "train = create_dummies(train,\"Pclass\")\n",
    "test = create_dummies(test,\"Pclass\")\n",
    "\n",
    "train = create_dummies(train,\"Sex\")\n",
    "test = create_dummies(test,\"Sex\")\n",
    "\n",
    "train = create_dummies(train,\"Age_categories\")\n",
    "test = create_dummies(test,\"Age_categories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3c0ba590c8e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "       'Age_categories_Missing','Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train[columns], train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = test # from now on we will refer to this\n",
    "               # dataframe as the holdout data\n",
    "\n",
    "from sklearn.model_selection import train_test_split # This will enable us to split our training data into two : \n",
    "                                                     # 1. One part to train our model on (often 80% of the observations) \n",
    "                                                     # 2. One part to make predictions with and test our model \n",
    "                                                     # (often 20% of the observations)\n",
    "\n",
    "columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "       'Age_categories_Missing','Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior']\n",
    "\n",
    "all_X = train[columns]\n",
    "all_y = train['Survived']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    all_X, all_y, test_size=0.2,random_state=0)\n",
    "\n",
    "# IMPORTANT : We do not make predictions on the training data directly to avoid OVERFITTING :  it will perform well because \n",
    "# we're testing on the same data we've trained on, but then perform much worse on new, unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
